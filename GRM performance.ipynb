{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas_gbq\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, confusion_matrix, precision_recall_curve, roc_auc_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [],
   "source": [
    "q='''\n",
    "WITH\n",
    "  cust_orders AS (\n",
    "  SELECT\n",
    "    analytical_customer_id,\n",
    "    lifecycle_segment,\n",
    "    global_entity_id,\n",
    "    reordered\n",
    "  FROM\n",
    "    `fulfillment-dwh-production.cl_mkt._reorder_lifecycle_segmentation_history`\n",
    "  LEFT JOIN (\n",
    "    SELECT\n",
    "      DISTINCT global_entity_id,\n",
    "      analytical_customer_id,\n",
    "      1 AS reordered,\n",
    "    FROM\n",
    "      `fulfillment-dwh-production.curated_data_shared_coredata_business.orders`\n",
    "    WHERE\n",
    "      partition_date_local = \"2023-09-01\"\n",
    "      AND global_entity_id=\"FP_TH\"\n",
    "      AND is_successful\n",
    "      AND analytical_customer_id IS NOT NULL )\n",
    "  USING\n",
    "    (analytical_customer_id,\n",
    "      global_entity_id)\n",
    "  WHERE computation_date = \"2023-09-01\" and global_entity_id=\"FP_TH\" ),\n",
    "  pred_scores AS (\n",
    "  SELECT\n",
    "    \"general_reorder\" AS model_type,\n",
    "    global_entity_id,\n",
    "    analytical_customer_id,\n",
    "    1 - concated_survival_scores[ORDINAL(30)] AS reorder_score,\n",
    "    scoring_date\n",
    "  FROM\n",
    "    `mkt-reorder-prod.mkt_reorder_prod.predictions_rsf_mature_targeted_ALL`\n",
    "  WHERE\n",
    "    scoring_date = \"2023-09-01\"\n",
    "    AND global_entity_id=\"FP_TH\" ),\n",
    "  merged_table AS (\n",
    "  SELECT\n",
    "    p.global_entity_id,\n",
    "    p.analytical_customer_id,\n",
    "    COALESCE(c.reordered, 0) AS reordered,\n",
    "    p.reorder_score*100 AS reorder_score,\n",
    "    p.model_type,\n",
    "    c.lifecycle_segment\n",
    "  FROM\n",
    "    pred_scores AS p\n",
    "  LEFT JOIN (\n",
    "    SELECT\n",
    "      *\n",
    "    FROM\n",
    "      cust_orders ) AS c\n",
    "  ON\n",
    "    p.global_entity_id = c.global_entity_id\n",
    "    AND p.analytical_customer_id = c.analytical_customer_id ),\n",
    "  binned_table AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    CASE\n",
    "      WHEN reorder_score < 10 THEN \"[0,10)\"\n",
    "      WHEN reorder_score >= 10\n",
    "    AND reorder_score < 20 THEN \"[10,20)\"\n",
    "      WHEN reorder_score >= 20 AND reorder_score < 30 THEN \"[20,30)\"\n",
    "      WHEN reorder_score >= 30\n",
    "    AND reorder_score < 40 THEN \"[30,40)\"\n",
    "      WHEN reorder_score >= 40 AND reorder_score < 50 THEN \"[40,50)\"\n",
    "      WHEN reorder_score >= 50\n",
    "    AND reorder_score < 60 THEN \"[50,60)\"\n",
    "      WHEN reorder_score >= 60 AND reorder_score < 70 THEN \"[60,70)\"\n",
    "      WHEN reorder_score >= 70\n",
    "    AND reorder_score < 80 THEN \"[70,80)\"\n",
    "      WHEN reorder_score >= 80 AND reorder_score < 90 THEN \"[80,90)\"\n",
    "      WHEN reorder_score >= 90 THEN \"[90,100)\"\n",
    "    ELSE\n",
    "    \"invalid_value\"\n",
    "  END\n",
    "    AS reorder_bin,\n",
    "  FROM\n",
    "    merged_table ),\n",
    "  min_max_reorder AS (\n",
    "  SELECT\n",
    "    global_entity_id,\n",
    "    model_type,\n",
    "    -- lifecycle_segment,\n",
    "    MAX(reorder_score) AS max_reorder_score,\n",
    "    MIN(reorder_score) AS min_reorder_score\n",
    "  FROM\n",
    "    binned_table\n",
    "  GROUP BY\n",
    "    model_type,\n",
    "    global_entity_id--, lifecycle_segment\n",
    "    )\n",
    "SELECT\n",
    "  r.global_entity_id,\n",
    "  r.analytical_customer_id,\n",
    "  r.reordered,\n",
    "  r.reorder_score,\n",
    "  r.model_type,\n",
    "  r.reorder_bin,\n",
    "  (r.reorder_score - m.min_reorder_score)/(m.max_reorder_score - m.min_reorder_score) AS reorder_score_scaled,\n",
    "  r.lifecycle_segment\n",
    "FROM\n",
    "  binned_table AS r\n",
    "JOIN\n",
    "  min_max_reorder AS m\n",
    "ON\n",
    "  m.model_type = r.model_type\n",
    "  AND m.global_entity_id = r.global_entity_id\n",
    "  --AND m.lifecycle_segment = r.lifecycle_segment\n",
    "ORDER BY\n",
    "  r.global_entity_id DESC,\n",
    "  r.analytical_customer_id DESC\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|\u001B[32m██████████\u001B[0m|\n"
     ]
    }
   ],
   "source": [
    "df = pandas_gbq.read_gbq(q)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [
    {
     "data": {
      "text/plain": "        global_entity_id  analytical_customer_id  reordered  reorder_score  \\\n2135464            FP_TH  --0--h2aUA6-Z2rRG0q7Mw          0           48.0   \n2135465            FP_TH  ---W4mtDUEmZ2ZqJ4cN_1Q          1           36.0   \n2135466            FP_TH  ---VrpoIXLW82Kim2fVx7w          0           13.0   \n2135467            FP_TH  ---1oqCLVmicpzN-udXAAQ          0           18.0   \n2135468            FP_TH  ----TV1zUBW00O6T2942TA          0           18.0   \n\n              model_type reorder_bin  reorder_score_scaled  \\\n2135464  general_reorder     [40,50)              0.430233   \n2135465  general_reorder     [30,40)              0.290698   \n2135466  general_reorder     [10,20)              0.023256   \n2135467  general_reorder     [10,20)              0.081395   \n2135468  general_reorder     [10,20)              0.081395   \n\n                  lifecycle_segment  \n2135464      dormant_early_customer  \n2135465  infrequent_mature_customer  \n2135466      dormant_early_customer  \n2135467     dormant_mature_customer  \n2135468        stale_early_customer  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>global_entity_id</th>\n      <th>analytical_customer_id</th>\n      <th>reordered</th>\n      <th>reorder_score</th>\n      <th>model_type</th>\n      <th>reorder_bin</th>\n      <th>reorder_score_scaled</th>\n      <th>lifecycle_segment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2135464</th>\n      <td>FP_TH</td>\n      <td>--0--h2aUA6-Z2rRG0q7Mw</td>\n      <td>0</td>\n      <td>48.0</td>\n      <td>general_reorder</td>\n      <td>[40,50)</td>\n      <td>0.430233</td>\n      <td>dormant_early_customer</td>\n    </tr>\n    <tr>\n      <th>2135465</th>\n      <td>FP_TH</td>\n      <td>---W4mtDUEmZ2ZqJ4cN_1Q</td>\n      <td>1</td>\n      <td>36.0</td>\n      <td>general_reorder</td>\n      <td>[30,40)</td>\n      <td>0.290698</td>\n      <td>infrequent_mature_customer</td>\n    </tr>\n    <tr>\n      <th>2135466</th>\n      <td>FP_TH</td>\n      <td>---VrpoIXLW82Kim2fVx7w</td>\n      <td>0</td>\n      <td>13.0</td>\n      <td>general_reorder</td>\n      <td>[10,20)</td>\n      <td>0.023256</td>\n      <td>dormant_early_customer</td>\n    </tr>\n    <tr>\n      <th>2135467</th>\n      <td>FP_TH</td>\n      <td>---1oqCLVmicpzN-udXAAQ</td>\n      <td>0</td>\n      <td>18.0</td>\n      <td>general_reorder</td>\n      <td>[10,20)</td>\n      <td>0.081395</td>\n      <td>dormant_mature_customer</td>\n    </tr>\n    <tr>\n      <th>2135468</th>\n      <td>FP_TH</td>\n      <td>----TV1zUBW00O6T2942TA</td>\n      <td>0</td>\n      <td>18.0</td>\n      <td>general_reorder</td>\n      <td>[10,20)</td>\n      <td>0.081395</td>\n      <td>stale_early_customer</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [],
   "source": [
    "#df['orders_count'].fillna(0, inplace=True)\n",
    "df['lifecycle_segment'].fillna(\"no_segment\", inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [],
   "source": [
    "def model_evaluation_metrices(y_true, y_pred_binary, ypred_score):\n",
    "    \"\"\"\n",
    "    This function gives model evaluation metrices viz. cm,accuracy,recall,specificity,auc,f1_score\n",
    "\n",
    "        Parameters:\n",
    "            y_true(array/list/series): true target labels\n",
    "            y_pred_binary(array/list/series): prediction target label in binary labels(0/1)\n",
    "            ypred_score(array/list/series): prediction target scores\n",
    "\n",
    "        Returns:\n",
    "            accuracy(float): accuracy of the model\n",
    "            recall(float): recall of the model\n",
    "            specificity(float): specificity of the model\n",
    "            f1_score(float): f1_score of the model\n",
    "            precision(float): precision of the model\n",
    "            roc_auc(float): roc_auc of the model\n",
    "            precision_recall_auc(float): precision_recall_auc of the model\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred_binary)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    # auc = roc_auc_score(y_true,y_pred)\n",
    "    recall = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    precision = tp / (tp + fp)\n",
    "    accuracy = (tp + tn) / (tn + fp + fn + tp)\n",
    "    f1_score = (2 * tp) / (2 * tp + fp + fn)\n",
    "    # calculate precision-recall curve\n",
    "    precision_for_auc, recall_for_auc, thresholds_vals = precision_recall_curve(\n",
    "        y_true, y_pred_binary\n",
    "    )\n",
    "    # calculate precision-recall AUC\n",
    "    precision_recall_auc = auc(recall_for_auc, precision_for_auc)\n",
    "    roc_auc = roc_auc_score(y_true=y_true, y_score=ypred_score)\n",
    "\n",
    "    return (\n",
    "        round(accuracy, 2),\n",
    "        round(recall, 2),\n",
    "        round(specificity, 2),\n",
    "        round(f1_score, 2),\n",
    "        round(precision, 2),\n",
    "        round(roc_auc, 2),\n",
    "        round(precision_recall_auc, 2),\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "outputs": [],
   "source": [
    "def make_results(df, order_col):\n",
    "    df_store_final = pd.DataFrame(\n",
    "            columns=[\n",
    "                \"threshold\",\n",
    "                \"lifecycle_segment\",\n",
    "                \"accuracy\",\n",
    "                \"recall\",\n",
    "                \"specificity\",\n",
    "                \"f1_score\",\n",
    "                \"precision\",\n",
    "                \"roc_auc\",\n",
    "                \"precision_recall_auc\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    for orders in df[order_col].unique():\n",
    "        df_orders = df[df[order_col]==orders]\n",
    "        for mythres in [0.3, 0.5, 0.7]:\n",
    "            binary_pred = df_orders[\"reorder_score_scaled\"].apply(\n",
    "                lambda x: 1 if x > mythres else 0\n",
    "            )\n",
    "            if (df_orders[\"reordered\"].nunique() < 2) | (\n",
    "                binary_pred.nunique() < 2 #understand condition better\n",
    "            ):\n",
    "                continue\n",
    "\n",
    "            (\n",
    "                accuracy,\n",
    "                recall,\n",
    "                specificity,\n",
    "                f1_score,\n",
    "                precision,\n",
    "                roc_auc,\n",
    "                precision_recall_auc,\n",
    "            ) = model_evaluation_metrices(\n",
    "                y_true=df_orders[\"reordered\"].to_list(),\n",
    "                y_pred_binary=binary_pred,\n",
    "                ypred_score=df_orders[\"reorder_score_scaled\"],\n",
    "        )\n",
    "\n",
    "            df_store = pd.DataFrame(\n",
    "                                index=[0],\n",
    "                                columns=[\n",
    "                                    \"threshold\",\n",
    "                                    \"lifecycle_segment\",\n",
    "                                    \"accuracy\",\n",
    "                                    \"recall\",\n",
    "                                    \"specificity\",\n",
    "                                    \"f1_score\",\n",
    "                                    \"precision\",\n",
    "                                    \"roc_auc\",\n",
    "                                    \"precision_recall_auc\",\n",
    "                                ],\n",
    "                            )\n",
    "            df_store[\"threshold\"] = mythres\n",
    "            df_store[\"lifecycle_segment\"] = orders\n",
    "            df_store[\"accuracy\"] = accuracy\n",
    "            df_store[\"recall\"] = recall\n",
    "            df_store[\"specificity\"] = specificity\n",
    "            df_store[\"f1_score\"] = f1_score\n",
    "            df_store[\"precision\"] = precision\n",
    "            df_store[\"roc_auc\"] = roc_auc\n",
    "            df_store[\"precision_recall_auc\"] = precision_recall_auc\n",
    "            df_store_final = pd.concat(\n",
    "                [df_store_final, df_store], axis=0, ignore_index=True\n",
    "            )\n",
    "    return df_store_final"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    threshold           lifecycle_segment  accuracy  recall  specificity  \\\n",
      "0         0.3  infrequent_mature_customer      0.49    0.84         0.48   \n",
      "1         0.5  infrequent_mature_customer      0.76    0.61         0.76   \n",
      "2         0.7  infrequent_mature_customer      0.90    0.33         0.92   \n",
      "3         0.3    frequent_mature_customer      0.31    0.98         0.23   \n",
      "4         0.5    frequent_mature_customer      0.48    0.95         0.42   \n",
      "5         0.7    frequent_mature_customer      0.63    0.87         0.60   \n",
      "6         0.3     dormant_mature_customer      0.96    0.03         0.97   \n",
      "7         0.3        stale_early_customer      0.89    0.50         0.90   \n",
      "8         0.5        stale_early_customer      0.96    0.24         0.97   \n",
      "9         0.7        stale_early_customer      0.99    0.01         1.00   \n",
      "10        0.3       recent_early_customer      0.49    0.86         0.47   \n",
      "11        0.5       recent_early_customer      0.85    0.44         0.87   \n",
      "12        0.7       recent_early_customer      0.95    0.08         0.99   \n",
      "13        0.3      dormant_early_customer      0.95    0.40         0.95   \n",
      "14        0.5      dormant_early_customer      0.99    0.11         0.99   \n",
      "\n",
      "    f1_score  precision  roc_auc  precision_recall_auc  \n",
      "0       0.09       0.05     0.75                  0.45  \n",
      "1       0.13       0.07     0.75                  0.35  \n",
      "2       0.17       0.11     0.75                  0.23  \n",
      "3       0.25       0.14     0.83                  0.56  \n",
      "4       0.30       0.18     0.83                  0.56  \n",
      "5       0.35       0.22     0.83                  0.55  \n",
      "6       0.01       0.00     0.56                  0.02  \n",
      "7       0.08       0.04     0.79                  0.27  \n",
      "8       0.10       0.07     0.79                  0.15  \n",
      "9       0.02       0.20     0.79                  0.11  \n",
      "10      0.13       0.07     0.75                  0.47  \n",
      "11      0.21       0.14     0.75                  0.30  \n",
      "12      0.12       0.26     0.75                  0.19  \n",
      "13      0.06       0.03     0.80                  0.22  \n",
      "14      0.09       0.07     0.80                  0.09  \n"
     ]
    }
   ],
   "source": [
    "results = make_results(df, order_col='lifecycle_segment')\n",
    "print(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Try left joining predictions on orders:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [],
   "source": [
    "q1 = '''\n",
    "WITH\n",
    "  cust_orders AS (\n",
    "  SELECT\n",
    "    analytical_customer_id,\n",
    "    lifecycle_segment,\n",
    "    global_entity_id,\n",
    "    reordered\n",
    "  FROM\n",
    "    `fulfillment-dwh-production.cl_mkt._reorder_lifecycle_segmentation_history`\n",
    "  LEFT JOIN (\n",
    "    SELECT\n",
    "      DISTINCT global_entity_id,\n",
    "      analytical_customer_id,\n",
    "      1 AS reordered,\n",
    "    FROM\n",
    "      `fulfillment-dwh-production.curated_data_shared_coredata_business.orders`\n",
    "    WHERE\n",
    "      partition_date_local = \"2023-09-01\"\n",
    "      AND global_entity_id=\"FP_TH\"\n",
    "      AND is_successful\n",
    "      AND analytical_customer_id IS NOT NULL )\n",
    "  USING\n",
    "    (analytical_customer_id,\n",
    "      global_entity_id)\n",
    "  WHERE computation_date = \"2023-09-01\" and global_entity_id=\"FP_TH\" ),\n",
    "  pred_scores AS (\n",
    "  SELECT\n",
    "    \"general_reorder\" AS model_type,\n",
    "    global_entity_id,\n",
    "    analytical_customer_id,\n",
    "    1 - concated_survival_scores[ORDINAL(30)] AS reorder_score,\n",
    "    scoring_date\n",
    "  FROM\n",
    "    `mkt-reorder-prod.mkt_reorder_prod.predictions_rsf_mature_targeted_ALL`\n",
    "  WHERE\n",
    "    scoring_date = \"2023-09-01\"\n",
    "    AND global_entity_id=\"FP_TH\" ),\n",
    "  merged_table AS (\n",
    "\n",
    "\n",
    "  SELECT\n",
    "    p.global_entity_id,\n",
    "    p.analytical_customer_id,\n",
    "    COALESCE(c.reordered, 0) AS reordered,\n",
    "    p.reorder_score*100 AS reorder_score,\n",
    "    p.model_type,\n",
    "    c.lifecycle_segment\n",
    "  FROM\n",
    "     cust_orders AS c\n",
    "  LEFT JOIN (\n",
    "    SELECT\n",
    "      global_entity_id,\n",
    "    analytical_customer_id,\n",
    "    reorder_score*100 AS reorder_score,\n",
    "    model_type,\n",
    "    FROM\n",
    "      pred_scores ) AS p\n",
    "  ON\n",
    "    p.global_entity_id = c.global_entity_id\n",
    "    AND p.analytical_customer_id = c.analytical_customer_id\n",
    "\n",
    "\n",
    "\n",
    "    ),\n",
    "  binned_table AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    CASE\n",
    "      WHEN reorder_score < 10 THEN \"[0,10)\"\n",
    "      WHEN reorder_score >= 10\n",
    "    AND reorder_score < 20 THEN \"[10,20)\"\n",
    "      WHEN reorder_score >= 20 AND reorder_score < 30 THEN \"[20,30)\"\n",
    "      WHEN reorder_score >= 30\n",
    "    AND reorder_score < 40 THEN \"[30,40)\"\n",
    "      WHEN reorder_score >= 40 AND reorder_score < 50 THEN \"[40,50)\"\n",
    "      WHEN reorder_score >= 50\n",
    "    AND reorder_score < 60 THEN \"[50,60)\"\n",
    "      WHEN reorder_score >= 60 AND reorder_score < 70 THEN \"[60,70)\"\n",
    "      WHEN reorder_score >= 70\n",
    "    AND reorder_score < 80 THEN \"[70,80)\"\n",
    "      WHEN reorder_score >= 80 AND reorder_score < 90 THEN \"[80,90)\"\n",
    "      WHEN reorder_score >= 90 THEN \"[90,100)\"\n",
    "    ELSE\n",
    "    \"invalid_value\"\n",
    "  END\n",
    "    AS reorder_bin,\n",
    "  FROM\n",
    "    merged_table ),\n",
    "  min_max_reorder AS (\n",
    "  SELECT\n",
    "    global_entity_id,\n",
    "    model_type,\n",
    "    -- lifecycle_segment,\n",
    "    MAX(reorder_score) AS max_reorder_score,\n",
    "    MIN(reorder_score) AS min_reorder_score\n",
    "  FROM\n",
    "    binned_table\n",
    "  GROUP BY\n",
    "    model_type,\n",
    "    global_entity_id--, lifecycle_segment\n",
    "    )\n",
    "SELECT\n",
    "  r.global_entity_id,\n",
    "  r.analytical_customer_id,\n",
    "  r.reordered,\n",
    "  r.reorder_score,\n",
    "  r.model_type,\n",
    "  r.reorder_bin,\n",
    "  (r.reorder_score - m.min_reorder_score)/(m.max_reorder_score - m.min_reorder_score) AS reorder_score_scaled,\n",
    "  r.lifecycle_segment\n",
    "FROM\n",
    "  binned_table AS r\n",
    "JOIN\n",
    "  min_max_reorder AS m\n",
    "ON\n",
    "  m.model_type = r.model_type\n",
    "  AND m.global_entity_id = r.global_entity_id\n",
    "  --AND m.lifecycle_segment = r.lifecycle_segment\n",
    "ORDER BY\n",
    "  r.global_entity_id DESC,\n",
    "  r.analytical_customer_id DESC\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|\u001B[32m██████████\u001B[0m|\n"
     ]
    }
   ],
   "source": [
    "df1 = pandas_gbq.read_gbq(q1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [],
   "source": [
    "df1['lifecycle_segment'].fillna(\"no_segment\", inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    threshold           lifecycle_segment  accuracy  recall  specificity  \\\n",
      "0         0.3  infrequent_mature_customer      0.49    0.84         0.48   \n",
      "1         0.5  infrequent_mature_customer      0.76    0.61         0.76   \n",
      "2         0.7  infrequent_mature_customer      0.90    0.33         0.92   \n",
      "3         0.3    frequent_mature_customer      0.31    0.98         0.23   \n",
      "4         0.5    frequent_mature_customer      0.48    0.95         0.42   \n",
      "5         0.7    frequent_mature_customer      0.63    0.87         0.60   \n",
      "6         0.3     dormant_mature_customer      0.96    0.03         0.97   \n",
      "7         0.3        stale_early_customer      0.89    0.50         0.90   \n",
      "8         0.5        stale_early_customer      0.96    0.24         0.97   \n",
      "9         0.7        stale_early_customer      0.99    0.01         1.00   \n",
      "10        0.3       recent_early_customer      0.49    0.86         0.47   \n",
      "11        0.5       recent_early_customer      0.85    0.44         0.87   \n",
      "12        0.7       recent_early_customer      0.95    0.08         0.99   \n",
      "13        0.3      dormant_early_customer      0.95    0.40         0.95   \n",
      "14        0.5      dormant_early_customer      0.99    0.11         0.99   \n",
      "\n",
      "    f1_score  precision  roc_auc  precision_recall_auc  \n",
      "0       0.09       0.05     0.75                  0.45  \n",
      "1       0.13       0.07     0.75                  0.35  \n",
      "2       0.17       0.11     0.75                  0.23  \n",
      "3       0.25       0.14     0.83                  0.56  \n",
      "4       0.30       0.18     0.83                  0.56  \n",
      "5       0.35       0.22     0.83                  0.55  \n",
      "6       0.01       0.00     0.56                  0.02  \n",
      "7       0.08       0.04     0.79                  0.27  \n",
      "8       0.10       0.07     0.79                  0.15  \n",
      "9       0.02       0.20     0.79                  0.11  \n",
      "10      0.13       0.07     0.75                  0.47  \n",
      "11      0.21       0.14     0.75                  0.30  \n",
      "12      0.12       0.26     0.75                  0.19  \n",
      "13      0.06       0.03     0.80                  0.22  \n",
      "14      0.09       0.07     0.80                  0.09  \n"
     ]
    }
   ],
   "source": [
    "results1 = make_results(df1, order_col='lifecycle_segment')\n",
    "print(results1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The df are the same"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
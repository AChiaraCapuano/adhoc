{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas_gbq\n",
    "import pandas as pd\n",
    "from sklearn.metrics import auc, confusion_matrix, precision_recall_curve, roc_auc_score\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following functions to calculate the model performance can be found at https://github.com/deliveryhero/datahub-airflow/blob/main/dags/mkt/mkt_reorder_performance_pipeline.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def model_evaluation_metrices(y_true, y_pred_binary, ypred_score):\n",
    "    cm = confusion_matrix(y_true, y_pred_binary)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    # auc = roc_auc_score(y_true,y_pred)\n",
    "    recall = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    precision = tp / (tp + fp)\n",
    "    accuracy = (tp + tn) / (tn + fp + fn + tp)\n",
    "    f1_score = (2 * tp) / (2 * tp + fp + fn)\n",
    "    # calculate precision-recall curve\n",
    "    precision_for_auc, recall_for_auc, thresholds_vals = precision_recall_curve(\n",
    "        y_true, y_pred_binary\n",
    "    )\n",
    "    # calculate precision-recall AUC\n",
    "    precision_recall_auc = auc(recall_for_auc, precision_for_auc)\n",
    "    roc_auc = roc_auc_score(y_true=y_true, y_score=ypred_score)\n",
    "\n",
    "    return (\n",
    "        round(accuracy, 2),\n",
    "        round(recall, 2),\n",
    "        round(specificity, 2),\n",
    "        round(f1_score, 2),\n",
    "        round(precision, 2),\n",
    "        round(roc_auc, 2),\n",
    "        round(precision_recall_auc, 2),\n",
    "    )\n",
    "\n",
    "def make_results(df, filter_col):\n",
    "    df_store_final = pd.DataFrame(\n",
    "            columns=[\n",
    "                \"threshold\",\n",
    "                \"global_entity_id\",\n",
    "                \"lifecycle_segment\",\n",
    "                \"accuracy\",\n",
    "                \"recall\",\n",
    "                \"specificity\",\n",
    "                \"f1_score\",\n",
    "                \"precision\",\n",
    "                \"roc_auc\",\n",
    "                \"precision_recall_auc\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    for segment in df[filter_col].unique():\n",
    "        df_filtered = df[df[filter_col]==segment]\n",
    "        for mythres in [0.3, 0.5, 0.7]:\n",
    "            binary_pred = df_filtered[\"reorder_score_scaled\"].apply(\n",
    "                lambda x: 1 if x > mythres else 0\n",
    "            )\n",
    "            if (df_filtered[\"reordered\"].nunique() < 2) | (\n",
    "                binary_pred.nunique() < 2\n",
    "            ):\n",
    "                continue\n",
    "\n",
    "            (\n",
    "                accuracy,\n",
    "                recall,\n",
    "                specificity,\n",
    "                f1_score,\n",
    "                precision,\n",
    "                roc_auc,\n",
    "                precision_recall_auc,\n",
    "            ) = model_evaluation_metrices(\n",
    "                y_true=df_filtered[\"reordered\"].to_list(),\n",
    "                y_pred_binary=binary_pred,\n",
    "                ypred_score=df_filtered[\"reorder_score_scaled\"],\n",
    "        )\n",
    "\n",
    "            df_store = pd.DataFrame(\n",
    "                                index=[0],\n",
    "                                columns=[\n",
    "                                    \"threshold\",\n",
    "                                    \"lifecycle_segment\",\n",
    "                                    \"global_entity_id\",\n",
    "                                    \"accuracy\",\n",
    "                                    \"recall\",\n",
    "                                    \"specificity\",\n",
    "                                    \"f1_score\",\n",
    "                                    \"precision\",\n",
    "                                    \"roc_auc\",\n",
    "                                    \"precision_recall_auc\",\n",
    "                                ],\n",
    "                            )\n",
    "            df_store[\"threshold\"] = mythres\n",
    "            df_store[\"lifecycle_segment\"] = segment\n",
    "            df_store[\"global_entity_id\"] = global_entity_id\n",
    "            df_store[\"accuracy\"] = accuracy\n",
    "            df_store[\"recall\"] = recall\n",
    "            df_store[\"specificity\"] = specificity\n",
    "            df_store[\"f1_score\"] = f1_score\n",
    "            df_store[\"precision\"] = precision\n",
    "            df_store[\"roc_auc\"] = roc_auc\n",
    "            df_store[\"precision_recall_auc\"] = precision_recall_auc\n",
    "            df_store_final = pd.concat(\n",
    "                [df_store_final, df_store], axis=0, ignore_index=True\n",
    "            )\n",
    "    return df_store_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_terms = [\n",
    "    \"PY_AR\", \"PY_BO\", \"PY_CL\", \"PY_CR\", \"PY_DO\", \"PY_EC\", \"PY_GT\", \n",
    "    \"PY_HN\", \"AP_PA\", \"PY_PE\", \"PY_PY\", \"PY_SV\", \"PY_UY\", \"PY_VE\", \n",
    "    \"PY_NI\", \"HS_SA\", \"IN_AE\", \"IN_OM\", \"IN_QA\", \"IN_BH\", \"IN_EG\", \n",
    "    \"TB_AE\", \"TB_BH\", \"HF_EG\", \"TB_IQ\", \"TB_JO\", \"FP_HK\", \"FP_BD\", \"FP_TH\", \"FP_TW\", \"FP_SG\", \"FP_PH\", \"FP_PK\", \n",
    "    \"FP_MY\", \"FP_LA\", \"FP_MM\", \"FP_KH\", \"YS_TR\", \"PY_GT\", \"DJ_CZ\", \"FP_KH\", \"HS_SA\", \"OP_SE\", \"PY_CL\", \"PY_PE\", \"PY_EC\", \"TB_OM\", \"PY_CR\", \n",
    "    \"PY_SV\", \"PY_DO\", \"IN_QA\", \"PY_HN\", \"FP_BD\", \"PY_UY\", \"IN_EG\", \"FP_TH\", \"FP_PH\", \"FO_NO\", \n",
    "    \"FP_LA\", \"IN_LB\", \"FP_MM\", \"FP_SG\", \"PO_FI\", \"PY_BO\", \"MJM_AT\", \"TB_IQ\", \"IN_AE\", \"FP_PK\", \n",
    "    \"IN_BH\", \"IN_OM\", \"NP_HU\", \"TB_BH\", \"EF_GR\", \"TB_KW\", \"AP_PA\", \"HF_EG\", \"TB_QA\", \"PY_AR\", \n",
    "    \"TB_AE\", \"FP_HK\", \"FP_MY\", \"TB_JO\", \"FY_CY\", \"FP_TW\", \"CG_QA\", \"YS_TR\", \"PY_PY\"\n",
    "]\n",
    "entities = list(set(all_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gid in entities:\n",
    "    q=f'''\n",
    "WITH\n",
    "  cust_orders AS (\n",
    "  SELECT\n",
    "    global_entity_id,\n",
    "    analytical_customer_id,\n",
    "    placed_at_local,\n",
    "    1 AS reordered,\n",
    "    CASE\n",
    "      WHEN is_discount OR is_voucher THEN 1\n",
    "    ELSE\n",
    "    0\n",
    "  END\n",
    "    AS is_incentivized_reorder,\n",
    "    CASE\n",
    "      WHEN is_discount OR is_voucher THEN 0\n",
    "    ELSE\n",
    "    1\n",
    "  END\n",
    "    AS is_organic_reorder,\n",
    "    CONCAT(EXTRACT(MONTH\n",
    "      FROM\n",
    "        placed_at_local),\"-\",EXTRACT(YEAR\n",
    "      FROM\n",
    "        placed_at_local)) AS month_year,\n",
    "  FROM\n",
    "    `fulfillment-dwh-production.curated_data_shared_coredata_business.orders`\n",
    "  WHERE\n",
    "    partition_date_local BETWEEN DATE_TRUNC(DATE_SUB('2024-01-01', INTERVAL 1 MONTH), MONTH)\n",
    "    AND DATE_ADD(DATE_TRUNC(DATE_SUB('2024-01-01', INTERVAL 1 MONTH), MONTH), INTERVAL 27 DAY)\n",
    "    AND is_successful\n",
    "    AND analytical_customer_id IS NOT NULL\n",
    "    AND global_entity_id IN UNNEST(['{gid}']) ),\n",
    "  cust_first_order_each_month AS (\n",
    "  SELECT\n",
    "    * EXCEPT(placed_at_local),\n",
    "    ROW_NUMBER() OVER (PARTITION BY analytical_customer_id, month_year ORDER BY placed_at_local) AS row_num,\n",
    "  FROM\n",
    "    cust_orders ),\n",
    "  recency AS (\n",
    "  SELECT\n",
    "    global_entity_id,\n",
    "    analytical_customer_id,\n",
    "    DATE_DIFF(DATE_TRUNC(DATE_SUB('2024-01-01', INTERVAL 1 MONTH), MONTH), MIN(placed_at_local), DAY) AS first_order_recency,\n",
    "    COUNT(DISTINCT order_id) AS orders\n",
    "  FROM\n",
    "    `fulfillment-dwh-production.curated_data_shared_coredata_business.orders`\n",
    "  WHERE\n",
    "    is_successful IS TRUE\n",
    "    AND analytical_customer_id IS NOT NULL\n",
    "    AND global_entity_id IN UNNEST(['{gid}'])\n",
    "    AND DATE(partition_date_local) <= DATE_TRUNC(DATE_SUB('2024-01-01', INTERVAL 1 MONTH), MONTH)\n",
    "  GROUP BY\n",
    "    global_entity_id,\n",
    "    analytical_customer_id ),\n",
    "  pred_scores_general AS (\n",
    "  SELECT\n",
    "    \"general_reorder\" AS model_type,\n",
    "    global_entity_id,\n",
    "    analytical_customer_id,\n",
    "    1 - concated_survival_scores[ORDINAL(28)] AS reorder_score,\n",
    "    scoring_date,\n",
    "    CONCAT(EXTRACT(MONTH\n",
    "      FROM\n",
    "        scoring_date),\"-\",EXTRACT(YEAR\n",
    "      FROM\n",
    "        scoring_date)) AS month_year\n",
    "  FROM\n",
    "    `mkt-reorder-prod.mkt_reorder_prod.predictions_rsf_mature_targeted_ALL`\n",
    "  WHERE\n",
    "    scoring_date IN (DATE_TRUNC(DATE_SUB('2024-01-01', INTERVAL 1 MONTH), MONTH)) ),\n",
    "  pred_scores_no_segments AS (\n",
    "  SELECT\n",
    "    *\n",
    "  FROM\n",
    "    pred_scores_general ),\n",
    "  pred_scores AS (\n",
    "  SELECT\n",
    "    p.*,\n",
    "    h.orders,\n",
    "    h.first_order_recency\n",
    "  FROM\n",
    "    pred_scores_no_segments p\n",
    "  LEFT JOIN (\n",
    "    SELECT\n",
    "      analytical_customer_id,\n",
    "      global_entity_id,\n",
    "      orders,\n",
    "      first_order_recency\n",
    "    FROM\n",
    "      recency \n",
    "     -- WHERE orders in (1,2,3,4,5,6,7,8,9,10) and first_order_recency in (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15)\n",
    "      ) h\n",
    "  ON\n",
    "    h.analytical_customer_id = p.analytical_customer_id\n",
    "    AND h.global_entity_id = p.global_entity_id ),\n",
    "  merged_table AS (\n",
    "  SELECT\n",
    "    p.global_entity_id,\n",
    "    p.analytical_customer_id,\n",
    "    COALESCE(c.reordered, 0) AS reordered,\n",
    "    p.month_year,\n",
    "    p.reorder_score*100 AS reorder_score,\n",
    "    p.model_type,\n",
    "    p.orders,\n",
    "    p.first_order_recency\n",
    "  FROM\n",
    "    pred_scores AS p\n",
    "  LEFT JOIN (\n",
    "    SELECT\n",
    "      * EXCEPT(row_num)\n",
    "    FROM\n",
    "      cust_first_order_each_month\n",
    "    WHERE\n",
    "      row_num = 1 ) AS c\n",
    "  ON\n",
    "    p.global_entity_id = c.global_entity_id\n",
    "    AND p.analytical_customer_id = c.analytical_customer_id\n",
    "    AND p.month_year = c.month_year ),\n",
    "  binned_table AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    CASE\n",
    "      WHEN reorder_score < 10 THEN \"[0,10)\"\n",
    "      WHEN reorder_score >= 10\n",
    "    AND reorder_score < 20 THEN \"[10,20)\"\n",
    "      WHEN reorder_score >= 20 AND reorder_score < 30 THEN \"[20,30)\"\n",
    "      WHEN reorder_score >= 30\n",
    "    AND reorder_score < 40 THEN \"[30,40)\"\n",
    "      WHEN reorder_score >= 40 AND reorder_score < 50 THEN \"[40,50)\"\n",
    "      WHEN reorder_score >= 50\n",
    "    AND reorder_score < 60 THEN \"[50,60)\"\n",
    "      WHEN reorder_score >= 60 AND reorder_score < 70 THEN \"[60,70)\"\n",
    "      WHEN reorder_score >= 70\n",
    "    AND reorder_score < 80 THEN \"[70,80)\"\n",
    "      WHEN reorder_score >= 80 AND reorder_score < 90 THEN \"[80,90)\"\n",
    "      WHEN reorder_score >= 90 THEN \"[90,100)\"\n",
    "    ELSE\n",
    "    \"invalid_value\"\n",
    "  END\n",
    "    AS reorder_bin,\n",
    "  FROM\n",
    "    merged_table ),\n",
    "  min_max_reorder AS (\n",
    "  SELECT\n",
    "    global_entity_id,\n",
    "    model_type,\n",
    "    month_year,\n",
    "    MAX(reorder_score) AS max_reorder_score,\n",
    "    MIN(reorder_score) AS min_reorder_score\n",
    "  FROM\n",
    "    binned_table\n",
    "  GROUP BY\n",
    "    model_type,\n",
    "    global_entity_id,\n",
    "    month_year )\n",
    "SELECT\n",
    "  r.global_entity_id,\n",
    "  r.analytical_customer_id,\n",
    "  r.reordered,\n",
    "  r.month_year,\n",
    "  r.reorder_score,\n",
    "  r.model_type,\n",
    "  r.reorder_bin,\n",
    "  (r.reorder_score - m.min_reorder_score)/(m.max_reorder_score - m.min_reorder_score) AS reorder_score_scaled,\n",
    "  r.orders,\n",
    "  r.first_order_recency\n",
    "FROM\n",
    "  binned_table AS r\n",
    "JOIN\n",
    "  min_max_reorder AS m\n",
    "ON\n",
    "  m.model_type = r.model_type\n",
    "  AND m.global_entity_id = r.global_entity_id\n",
    "  AND m.month_year = r.month_year\n",
    "'''\n",
    "    df = pandas_gbq.read_gbq(q)\n",
    "    print(df.head)\n",
    "    results = make_results(df, filter_col='orders')\n",
    "    results_rec = make_results(df, filter_col='first_order_recency')\n",
    "    results.to_csv(f'order_num/{gid}_2024_01_01_performance_orders_number.csv')\n",
    "    results_rec.to_csv(f'order_rec/{gid}_2024_01_01_performance_first_order_recency.csv')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all csv files in target directory\n",
    "files = glob.glob('order_rec/*.csv')\n",
    "\n",
    "# Initialize an empty list to hold DataFrames\n",
    "df_list = []\n",
    "\n",
    "for file in files:\n",
    "    # Read each csv file and append it to the df_list\n",
    "    df_list.append(pd.read_csv(file))\n",
    "\n",
    "# Concatenate all dataframes in the list.\n",
    "concat_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Write the resultant DataFrame to a new CSV file\n",
    "concat_df.to_csv('all_countries_2024_01_01_performance_first_order_recency', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all csv files in target directory\n",
    "files1 = glob.glob('order_num/*.csv')\n",
    "\n",
    "# Initialize an empty list to hold DataFrames\n",
    "df_list1 = []\n",
    "\n",
    "for file in files:\n",
    "    # Read each csv file and append it to the df_list\n",
    "    df_list1.append(pd.read_csv(file1))\n",
    "\n",
    "# Concatenate all dataframes in the list.\n",
    "concat_df1 = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Write the resultant DataFrame to a new CSV file\n",
    "concat_df1.to_csv('all_countries_2024_01_01_performance_first_order_recency', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
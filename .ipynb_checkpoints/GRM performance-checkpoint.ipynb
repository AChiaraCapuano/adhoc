{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas_gbq\n",
    "import pandas as pd\n",
    "from sklearn.metrics import auc, confusion_matrix, precision_recall_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "q='''\n",
    "# 1-select users and respective segments for \"2023-09-01\"\n",
    "# 2-mark which users placed an order on \"2023-09-01\"\n",
    "with recency AS\n",
    "(\n",
    "SELECT      global_entity_id,\n",
    "            analytical_customer_id,\n",
    "            DATE(\"2023-09-01\") AS scoring_date,\n",
    "            DATE_DIFF(DATE(\"2023-09-01\"), MAX(placed_at_local), DAY) AS last_order_recency\n",
    "FROM        `fulfillment-dwh-production.curated_data_shared_central_dwh.orders`\n",
    "WHERE       is_sent IS TRUE\n",
    "            AND analytical_customer_id IS NOT NULL\n",
    "            AND global_entity_id =\"YS_TR\"\n",
    "            AND placed_at_local BETWEEN DATE_SUB(DATE(\"2023-09-01\"), INTERVAL 30 DAY) AND \"2023-09-01\"\n",
    "GROUP BY    global_entity_id,\n",
    "            analytical_customer_id\n",
    "),\n",
    "\n",
    "\n",
    "segments AS (SELECT  global_entity_id,\n",
    "        analytical_customer_id,\n",
    "        CASE\n",
    "            WHEN last_order_recency >= 25 THEN \"1_er\"\n",
    "            WHEN last_order_recency >= 10 AND last_order_recency <25  THEN \"low frequent\"\n",
    "            WHEN last_order_recency >= 7 AND last_order_recency <10  THEN \"mid frequent\"\n",
    "            WHEN last_order_recency <= 7  THEN \"frequent\"\n",
    "        END AS lifecycle_segment\n",
    "FROM    recency\n",
    "WHERE   last_order_recency <= 30\n",
    "),\n",
    "\n",
    "  cust_orders AS (\n",
    "  SELECT analytical_customer_id, lifecycle_segment, global_entity_id, reordered\n",
    "  FROM segments\n",
    "  LEFT JOIN (SELECT DISTINCT global_entity_id, analytical_customer_id, 1 AS reordered\n",
    "             FROM  `fulfillment-dwh-production.curated_data_shared_coredata_business.orders`\n",
    "                WHERE partition_date_local = \"2023-09-01\" AND global_entity_id=\"YS_TR\" AND is_successful AND analytical_customer_id IS NOT NULL )\n",
    "  USING(analytical_customer_id, global_entity_id)\n",
    "  WHERE snapshot_date = \"2023-09-01\" and global_entity_id=\"YS_TR\" ),\n",
    "\n",
    "# select reorder score predicted for users on \"2023-09-01\"\n",
    "  pred_scores AS (\n",
    "  SELECT\n",
    "    \"general_reorder\" AS model_type, global_entity_id, analytical_customer_id, 1 - concated_survival_scores[ORDINAL(1)] AS reorder_score, scoring_date\n",
    "  FROM `mkt-reorder-prod.mkt_reorder_prod.predictions_rsf_mature_targeted_ALL`\n",
    "    WHERE scoring_date = \"2023-09-01\" AND global_entity_id=\"YS_TR\"),\n",
    "\n",
    "# merge previous two tables\n",
    "# (when left joining pred_scores on cust_orders we lose the customers without segment. Otherwise the results are the same)\n",
    "  merged_table AS (\n",
    "  SELECT p.global_entity_id, p.analytical_customer_id, COALESCE(c.reordered, 0) AS reordered, p.reorder_score*100 AS reorder_score, p.model_type, c.lifecycle_segment\n",
    "  FROM pred_scores AS p\n",
    "  LEFT JOIN ( SELECT * FROM cust_orders ) AS c\n",
    "  ON p.global_entity_id = c.global_entity_id AND p.analytical_customer_id = c.analytical_customer_id),\n",
    "\n",
    "# calculate min/max reorder score to scale reorder probability\n",
    "  min_max_reorder AS (\n",
    "  SELECT global_entity_id, model_type, MAX(reorder_score) AS max_reorder_score, MIN(reorder_score) AS min_reorder_score\n",
    "  FROM merged_table GROUP BY  model_type, global_entity_id)\n",
    "\n",
    "# final results with scaled reorder probability, lifecycle segment and reorder score\n",
    "SELECT\n",
    "  r.global_entity_id,\n",
    "  r.analytical_customer_id,\n",
    "  r.reordered,\n",
    "  r.reorder_score,\n",
    "  r.model_type,\n",
    "  (r.reorder_score - m.min_reorder_score)/(m.max_reorder_score - m.min_reorder_score) AS reorder_score_scaled,\n",
    "  r.lifecycle_segment\n",
    "FROM merged_table AS r\n",
    "JOIN min_max_reorder AS m ON m.model_type = r.model_type AND m.global_entity_id = r.global_entity_id\n",
    "ORDER BY r.global_entity_id DESC, r.analytical_customer_id DESC\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pandas_gbq.read_gbq(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#df['orders_count'].fillna(0, inplace=True)\n",
    "df['lifecycle_segment'].fillna(\"no_segment\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following functions to calculate the model performance can be found at https://github.com/deliveryhero/datahub-airflow/blob/main/dags/mkt/mkt_reorder_performance_pipeline.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def model_evaluation_metrices(y_true, y_pred_binary, ypred_score):\n",
    "    cm = confusion_matrix(y_true, y_pred_binary)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    # auc = roc_auc_score(y_true,y_pred)\n",
    "    recall = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    precision = tp / (tp + fp)\n",
    "    accuracy = (tp + tn) / (tn + fp + fn + tp)\n",
    "    f1_score = (2 * tp) / (2 * tp + fp + fn)\n",
    "    # calculate precision-recall curve\n",
    "    precision_for_auc, recall_for_auc, thresholds_vals = precision_recall_curve(\n",
    "        y_true, y_pred_binary\n",
    "    )\n",
    "    # calculate precision-recall AUC\n",
    "    precision_recall_auc = auc(recall_for_auc, precision_for_auc)\n",
    "    roc_auc = roc_auc_score(y_true=y_true, y_score=ypred_score)\n",
    "\n",
    "    return (\n",
    "        round(accuracy, 2),\n",
    "        round(recall, 2),\n",
    "        round(specificity, 2),\n",
    "        round(f1_score, 2),\n",
    "        round(precision, 2),\n",
    "        round(roc_auc, 2),\n",
    "        round(precision_recall_auc, 2),\n",
    "    )\n",
    "\n",
    "def make_results(df, filter_col):\n",
    "    df_store_final = pd.DataFrame(\n",
    "            columns=[\n",
    "                \"threshold\",\n",
    "                \"lifecycle_segment\",\n",
    "                \"accuracy\",\n",
    "                \"recall\",\n",
    "                \"specificity\",\n",
    "                \"f1_score\",\n",
    "                \"precision\",\n",
    "                \"roc_auc\",\n",
    "                \"precision_recall_auc\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    for segment in df[filter_col].unique():\n",
    "        df_filtered = df[df[filter_col]==segment]\n",
    "        for mythres in [0.3, 0.5, 0.7]:\n",
    "            binary_pred = df_filtered[\"reorder_score_scaled\"].apply(\n",
    "                lambda x: 1 if x > mythres else 0\n",
    "            )\n",
    "            if (df_filtered[\"reordered\"].nunique() < 2) | (\n",
    "                binary_pred.nunique() < 2\n",
    "            ):\n",
    "                continue\n",
    "\n",
    "            (\n",
    "                accuracy,\n",
    "                recall,\n",
    "                specificity,\n",
    "                f1_score,\n",
    "                precision,\n",
    "                roc_auc,\n",
    "                precision_recall_auc,\n",
    "            ) = model_evaluation_metrices(\n",
    "                y_true=df_filtered[\"reordered\"].to_list(),\n",
    "                y_pred_binary=binary_pred,\n",
    "                ypred_score=df_filtered[\"reorder_score_scaled\"],\n",
    "        )\n",
    "\n",
    "            df_store = pd.DataFrame(\n",
    "                                index=[0],\n",
    "                                columns=[\n",
    "                                    \"threshold\",\n",
    "                                    \"lifecycle_segment\",\n",
    "                                    \"accuracy\",\n",
    "                                    \"recall\",\n",
    "                                    \"specificity\",\n",
    "                                    \"f1_score\",\n",
    "                                    \"precision\",\n",
    "                                    \"roc_auc\",\n",
    "                                    \"precision_recall_auc\",\n",
    "                                ],\n",
    "                            )\n",
    "            df_store[\"threshold\"] = mythres\n",
    "            df_store[\"lifecycle_segment\"] = segment\n",
    "            df_store[\"accuracy\"] = accuracy\n",
    "            df_store[\"recall\"] = recall\n",
    "            df_store[\"specificity\"] = specificity\n",
    "            df_store[\"f1_score\"] = f1_score\n",
    "            df_store[\"precision\"] = precision\n",
    "            df_store[\"roc_auc\"] = roc_auc\n",
    "            df_store[\"precision_recall_auc\"] = precision_recall_auc\n",
    "            df_store_final = pd.concat(\n",
    "                [df_store_final, df_store], axis=0, ignore_index=True\n",
    "            )\n",
    "    return df_store_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results = make_results(df, filter_col='lifecycle_segment')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['lifecycle_segment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
